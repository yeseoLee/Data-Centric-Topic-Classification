{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/sujin-5_base_noise_detected.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ì˜ë¯¸ ì—†ëŠ” ë¬¸ì ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>is_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>ì •i :íŒŒ1 ë¯¸ì‚¬z KT( ì´ìš©ê¸°ê°„ 2e ë‹¨] Që¶„ì¢…U</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>Kì°°.êµ­DLwo ë¡œL3í•œN% íšŒì¥ 2 T0&amp;}ì†¡=</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m ê¹€ì •) ìì£¼í†µì¼ ìƒˆ,?rì—´1ë‚˜ê°€ì•¼</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µâ€¦ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pIç¾ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ] $ë¹„í•´ ê°ì‹œ ê°•í™”</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                            text  target  is_noise\n",
       "0  ynat-v1_train_00000  ì •i :íŒŒ1 ë¯¸ì‚¬z KT( ì´ìš©ê¸°ê°„ 2e ë‹¨] Që¶„ì¢…U       4         1\n",
       "1  ynat-v1_train_00001     Kì°°.êµ­DLwo ë¡œL3í•œN% íšŒì¥ 2 T0&}ì†¡=       3         1\n",
       "2  ynat-v1_train_00002            m ê¹€ì •) ìì£¼í†µì¼ ìƒˆ,?rì—´1ë‚˜ê°€ì•¼       2         1\n",
       "3  ynat-v1_train_00003   ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µâ€¦ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©       5         0\n",
       "4  ynat-v1_train_00004    pIç¾ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ] $ë¹„í•´ ê°ì‹œ ê°•í™”       6         1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text ì•ë’¤ì— ê·¸ë˜í”½/ê²Œì‹œíŒ/ì¢…í•© ë“±ì˜ ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ê°€ ë‚˜ì˜¤ëŠ” ê²½ìš° ì‚­ì œ\n",
    "df[\"text\"] = df[\"text\"].replace(r\"^(ê·¸ë˜í”½|ê²Œì‹œíŒ)\", \"\", regex=True)\n",
    "df[\"text\"] = df[\"text\"].replace(r\"^(ì¢…í•©|1ë³´|2ë³´|3ë³´)\", \"\", regex=True)\n",
    "df[\"text\"] = df[\"text\"].replace(r\"(ì¢…í•©|ì¢…í•©1ë³´|ì¢…í•©2ë³´|1ë³´|2ë³´|3ë³´)$\", \"\", regex=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>is_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>ì •i :íŒŒ1 ë¯¸ì‚¬z KT( ì´ìš©ê¸°ê°„ 2e ë‹¨] Që¶„ì¢…U</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>Kì°°.êµ­DLwo ë¡œL3í•œN% íšŒì¥ 2 T0&amp;}ì†¡=</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m ê¹€ì •) ìì£¼í†µì¼ ìƒˆ,?rì—´1ë‚˜ê°€ì•¼</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pIç¾ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ] $ë¹„í•´ ê°ì‹œ ê°•í™”</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                            text  target  is_noise\n",
       "0  ynat-v1_train_00000  ì •i :íŒŒ1 ë¯¸ì‚¬z KT( ì´ìš©ê¸°ê°„ 2e ë‹¨] Që¶„ì¢…U       4         1\n",
       "1  ynat-v1_train_00001     Kì°°.êµ­DLwo ë¡œL3í•œN% íšŒì¥ 2 T0&}ì†¡=       3         1\n",
       "2  ynat-v1_train_00002            m ê¹€ì •) ìì£¼í†µì¼ ìƒˆ,?rì—´1ë‚˜ê°€ì•¼       2         1\n",
       "3  ynat-v1_train_00003   ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©       5         0\n",
       "4  ynat-v1_train_00004    pIç¾ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ] $ë¹„í•´ ê°ì‹œ ê°•í™”       6         1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë§ì¤„ì„í‘œ: ë„ì–´ì“°ê¸° ì²˜ë¦¬ í˜¹ì€ ì œê±°\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"â€¦\", \" \")\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"...\", \"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë…¸ì´ì¦ˆ ë¬¸ì¥ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# ì˜ì–´, ìˆ«ì, í•œê¸€, í•œì ì œì™¸ ì œê±°\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r\"[^a-zA-Z0-9\\sã„±-ã…ã…-ã…£ê°€-í£\\u4e00-\\u9fff]\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>is_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pIç¾ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                           text  target  is_noise\n",
       "0  ynat-v1_train_00000    ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U       4         1\n",
       "1  ynat-v1_train_00001         Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡       3         1\n",
       "2  ynat-v1_train_00002              m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼       2         1\n",
       "3  ynat-v1_train_00003  ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©       5         0\n",
       "4  ynat-v1_train_00004     pIç¾ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”       6         1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë…¸ì´ì¦ˆ ë°ì´í„°ì—ë§Œ í•¨ìˆ˜ ì ìš©\n",
    "df.loc[df[\"is_noise\"] == 1, \"text\"] = df.loc[df[\"is_noise\"] == 1, \"text\"].apply(\n",
    "    remove_special_characters\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. í•œìëŠ” í•œê¸€ ëœ»ì„ í•¨ê»˜ ê¸°ì…í•˜ì—¬ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 ['ç¾', 'åŒ—', 'ä¸­', 'æœ´', 'é‘', 'æ—¥', 'èˆ‡', 'æ–‡', 'è‹±', 'é‡', 'ä½›', 'ä¼Š', 'ç¨', 'å', 'å‰', 'è»', 'ç¡', 'å°', 'å¤–', 'ç¤¾', 'é»ƒ', 'äº', 'éŸ“', 'æ ª', 'è»Š', 'å´”', 'é™¢', 'é‡‘', 'ä¸', 'å°', 'å’Œ', 'ä¼', 'å®‰', 'å±•', 'æª¢', 'è¦ª', 'éŠ€', 'è­‰', 'å…ˆ', 'çˆ¶', 'å—', 'è©©', 'å®¶', 'å¤§', 'å°', 'é˜¿', 'æ•…', 'å·', 'é‡']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# í•œì ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜\n",
    "def extract_hanza(text):\n",
    "    # CJK í†µí•© í•œì ë²”ìœ„(U+4E00 ~ U+9FFF)ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì ì¶”ì¶œ\n",
    "    return \"\".join(re.findall(\"[\\u4e00-\\u9fff]\", text))\n",
    "\n",
    "\n",
    "# ë¬¸ì ë¹ˆë„ ì¶•ì •\n",
    "def get_char_frequency(text_list):\n",
    "    # ëª¨ë“  ë¬¸ìë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°\n",
    "    chars = [char for text in text_list for char in text]\n",
    "    # Counterë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ˆë„ ê³„ì‚°\n",
    "    char_counts = Counter(chars)\n",
    "    # ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "    return pd.Series(char_counts).sort_values(ascending=False)\n",
    "\n",
    "# í•œì ë¹ˆë„ìˆ˜ ì¸¡ì •\n",
    "hanza = df[\"text\"].apply(extract_hanza)\n",
    "\n",
    "char_frequency = get_char_frequency(hanza)\n",
    "hanza = list(char_frequency.keys())\n",
    "print(len(hanza), hanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanza_hangul_meaning = [\n",
    "    ('ç¾', 'ë¯¸êµ­', 'ë‚˜ë¼'), ('åŒ—', 'ë¶í•œ', 'ë‚˜ë¼'), ('ä¸­', 'ì¤‘êµ­', 'ë‚˜ë¼'),\n",
    "    ('æœ´', 'ë°•', 'ì„±ì”¨'), ('é‘', 'ì²­ì™€ëŒ€', 'ì •ì¹˜'), ('æ—¥', 'ì¼ë³¸', 'ë‚˜ë¼'),\n",
    "    ('èˆ‡', 'ì—¬ë‹¹', 'ì •ì¹˜'), ('æ–‡', 'ë¬¸','ì„±ì”¨'), ('è‹±', 'ì˜êµ­', 'ë‚˜ë¼'),\n",
    "    ('é‡', 'ì•¼ë‹¹', 'ì •ì¹˜'), ('ä½›', 'í”„ë‘ìŠ¤', 'ë‚˜ë¼'), ('ä¼Š', 'ì´íƒˆë¦¬ì•„', 'ë‚˜ë¼'),\n",
    "    ('ç¨', 'ë…ì¼', 'ë‚˜ë¼'), ('å', 'ë°˜', 'ì¼ë°˜'), ('å‰', 'ì „', 'ì¼ë°˜'),\n",
    "    ('è»', 'êµ°ëŒ€', 'ì¼ë°˜'), ('ç¡', 'ì—°êµ¬ì›', 'ì¼ë°˜'), ('å°', 'ëŒ€', 'ì¼ë°˜'),\n",
    "    ('å¤–', 'ì™¸', 'ì¼ë°˜'), ('ç¤¾', 'íšŒì‚¬', 'ê²½ì œ'), ('é»ƒ', 'í™©','ì„±ì”¨'),\n",
    "    ('äº', 'ì•„ì‹œì•„', 'ë‚˜ë¼'), ('éŸ“', 'í•œêµ­', 'ë‚˜ë¼'), ('æ ª', 'ì£¼ì‹', 'ê²½ì œ'),\n",
    "    ('è»Š', 'ì°¨', 'ì¼ë°˜'), ('å´”', 'ìµœ','ì„±ì”¨'), ('é™¢', 'ìœ„ì›', 'ì¼ë°˜'),\n",
    "    ('é‡‘', 'ê¹€','ì„±ì”¨'), ('ä¸', 'ì •','ì„±ì”¨'), ('å°', 'ì†Œ', 'ì¼ë°˜'),\n",
    "    ('å’Œ', 'ë„¤ëœë€ë“œ', 'ë‚˜ë¼'), ('ä¼', 'ê¸°ì—…', 'ê²½ì œ'), ('å®‰', 'ì•ˆ','ì„±ì”¨'),\n",
    "    ('å±•', 'ì „ì‹œ', 'ì¼ë°˜'), ('æª¢', 'ê²€ì°°', 'ì •ì¹˜'), ('è¦ª', 'ì¹œ', 'ì¼ë°˜'),\n",
    "    ('éŠ€', 'ì€í–‰', 'ê²½ì œ'), ('è­‰', 'ì¦ê¶Œ', 'ê²½ì œ'), ('å…ˆ', 'ì„ ', 'ì¼ë°˜'),\n",
    "    ('çˆ¶', 'ì•„ë²„ì§€', 'ì¼ë°˜'), ('å—', 'ë‚¨í•œ', 'ë‚˜ë¼'), ('è©©', 'ì‹œ', 'ì¼ë°˜'),\n",
    "    ('å®¶', 'ì§‘ì•ˆ', 'ì¼ë°˜'), ('å¤§', 'ëŒ€', 'ì¼ë°˜'), ('å°', 'ì¸ë„', 'ë‚˜ë¼'),\n",
    "    ('é˜¿', 'ì•„í”„ë¦¬ì¹´', 'ë‚˜ë¼'), ('æ•…', 'ê³ ', 'ì¼ë°˜'), ('å·', 'ì£¼', 'ë‚˜ë¼'),\n",
    "    ('é‡', 'ì¤‘ê³µì—…', 'ê²½ì œ')\n",
    "]\n",
    "\n",
    "def annotate_hanzi_with_meaning(text):\n",
    "    for hanzi, hangul, _ in hanza_hangul_meaning:\n",
    "        text = text.replace(hanzi, f\"{hanzi}({hangul})\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>is_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pIç¾(ë¯¸êµ­)ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ynat-v1_train_00005</td>\n",
       "      <td>ç¾(ë¯¸êµ­)ì„±ì¸ 6ëª… ì¤‘ 1ëª…ê¼´ ë°°ìš°ìÂ·ì—°ì¸ ë¹š ë– ì•ˆì€ ì  ìˆë‹¤</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ynat-v1_train_00006</td>\n",
       "      <td>í”„ë¡œì•¼êµ¬ë¡¯TKIAsê´‘ì£¼ ê²½ê¸° yì²œì·¨ì†Œ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ynat-v1_train_00007</td>\n",
       "      <td>ì•„ê°€ë©”ì¦ˆ 33ë“ì  ìš°ë¦¬ì¹´ë“œ KBì†í•´ë³´í—˜ ì™„íŒŒ 3ìœ„ êµ³</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ynat-v1_train_00008</td>\n",
       "      <td>æœ´(ë°•)ëŒ€í†µë ¹ ì–¼ë§ˆë‚˜ ë§ì´ ë†€ë¼ì…¨ì–´ìš” ê²½ì£¼ ì§€ì§„í˜„ì¥ ë°©ë¬¸</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ynat-v1_train_00009</td>\n",
       "      <td>ë“€ì–¼ì‹¬ ì•„ì´í° í•˜ë°˜ê¸° ì¶œì‹œì„¤ ì†”ì†” ì•Œëœ°í° ê¸°ëŒ€ê°</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                text  target  is_noise\n",
       "0  ynat-v1_train_00000         ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U       4         1\n",
       "1  ynat-v1_train_00001              Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡       3         1\n",
       "2  ynat-v1_train_00002                   m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼       2         1\n",
       "3  ynat-v1_train_00003       ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©       5         0\n",
       "4  ynat-v1_train_00004      pIç¾(ë¯¸êµ­)ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”       6         1\n",
       "5  ynat-v1_train_00005  ç¾(ë¯¸êµ­)ì„±ì¸ 6ëª… ì¤‘ 1ëª…ê¼´ ë°°ìš°ìÂ·ì—°ì¸ ë¹š ë– ì•ˆì€ ì  ìˆë‹¤       0         0\n",
       "6  ynat-v1_train_00006                í”„ë¡œì•¼êµ¬ë¡¯TKIAsê´‘ì£¼ ê²½ê¸° yì²œì·¨ì†Œ       1         1\n",
       "7  ynat-v1_train_00007       ì•„ê°€ë©”ì¦ˆ 33ë“ì  ìš°ë¦¬ì¹´ë“œ KBì†í•´ë³´í—˜ ì™„íŒŒ 3ìœ„ êµ³       4         0\n",
       "8  ynat-v1_train_00008     æœ´(ë°•)ëŒ€í†µë ¹ ì–¼ë§ˆë‚˜ ë§ì´ ë†€ë¼ì…¨ì–´ìš” ê²½ì£¼ ì§€ì§„í˜„ì¥ ë°©ë¬¸       6         0\n",
       "9  ynat-v1_train_00009          ë“€ì–¼ì‹¬ ì•„ì´í° í•˜ë°˜ê¸° ì¶œì‹œì„¤ ì†”ì†” ì•Œëœ°í° ê¸°ëŒ€ê°       4         0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"text\"] = df[\"text\"].apply(annotate_hanzi_with_meaning)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"3_d_2800_hanzi_dictionary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. í˜•íƒœì†Œ ë¶„ì„ê¸°ë¡œ ë…¸ì´ì¦ˆ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/3_d_2800_hanzi_dictionary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1602\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>is_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pIç¾(ë¯¸êµ­)ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ynat-v1_train_00006</td>\n",
       "      <td>í”„ë¡œì•¼êµ¬ë¡¯TKIAsê´‘ì£¼ ê²½ê¸° yì²œì·¨ì†Œ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                            text  target  is_noise\n",
       "0  ynat-v1_train_00000     ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U       4         1\n",
       "1  ynat-v1_train_00001          Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡       3         1\n",
       "2  ynat-v1_train_00002               m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼       2         1\n",
       "4  ynat-v1_train_00004  pIç¾(ë¯¸êµ­)ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”       6         1\n",
       "6  ynat-v1_train_00006            í”„ë¡œì•¼êµ¬ë¡¯TKIAsê´‘ì£¼ ê²½ê¸° yì²œì·¨ì†Œ       1         1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"is_noise\"]==1]\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜•íƒœì†Œ ë¶„ì„ê¸° ì„í¬íŠ¸\n",
    "from konlpy.tag import *\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos_tagging\"] = df[\"text\"].copy()\n",
    "# ë‹¨ì–´ë³„ êµ¬ë¶„ ì—†ì´ í•œ ë¬¸ì¥ í†µìœ¼ë¡œ í•˜ë ¤ë©´\n",
    "# df[\"pos_tagging\"] = df[\"pos_tagging\"].apply(lambda text: okt.pos(text))\n",
    "# ë‹¨ì–´ë³„ë¡œ í˜•íƒœì†Œ ë¶„ì„ ì ìš©\n",
    "df[\"pos_tagging\"] = df[\"pos_tagging\"].apply(str.split)\n",
    "df[\"pos_tagging\"] = df[\"pos_tagging\"].apply(lambda li: [okt.pos(e) for e in li])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>is_noise</th>\n",
       "      <th>pos_tagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(ì •, Noun), (i, Alpha)], [(íŒŒ, Noun), (1, Numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(K, Alpha), (ì°°êµ­, Noun), (DLwo, Alpha)], [(ë¡œ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(m, Alpha)], [(ê¹€ì •, Noun)], [(ìì£¼, Noun), (í†µì¼,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pIç¾(ë¯¸êµ­)ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(pI, Alpha), (ç¾, Foreign), ((, Punctuation),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ynat-v1_train_00006</td>\n",
       "      <td>í”„ë¡œì•¼êµ¬ë¡¯TKIAsê´‘ì£¼ ê²½ê¸° yì²œì·¨ì†Œ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(í”„ë¡œì•¼êµ¬, Noun), (ë¡¯, Noun), (TKIAs, Alpha), (ê´‘ì£¼...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                            text  target  is_noise  \\\n",
       "0  ynat-v1_train_00000     ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U       4         1   \n",
       "1  ynat-v1_train_00001          Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡       3         1   \n",
       "2  ynat-v1_train_00002               m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼       2         1   \n",
       "4  ynat-v1_train_00004  pIç¾(ë¯¸êµ­)ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”       6         1   \n",
       "6  ynat-v1_train_00006            í”„ë¡œì•¼êµ¬ë¡¯TKIAsê´‘ì£¼ ê²½ê¸° yì²œì·¨ì†Œ       1         1   \n",
       "\n",
       "                                         pos_tagging  \n",
       "0  [[(ì •, Noun), (i, Alpha)], [(íŒŒ, Noun), (1, Numb...  \n",
       "1  [[(K, Alpha), (ì°°êµ­, Noun), (DLwo, Alpha)], [(ë¡œ,...  \n",
       "2  [[(m, Alpha)], [(ê¹€ì •, Noun)], [(ìì£¼, Noun), (í†µì¼,...  \n",
       "4  [[(pI, Alpha), (ç¾, Foreign), ((, Punctuation),...  \n",
       "6  [[(í”„ë¡œì•¼êµ¬, Noun), (ë¡¯, Noun), (TKIAs, Alpha), (ê´‘ì£¼...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>is_noise</th>\n",
       "      <th>pos_tagging</th>\n",
       "      <th>pos_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(ì •, Noun), (i, Alpha)], [(íŒŒ, Noun), (1, Numb...</td>\n",
       "      <td>ì • íŒŒ ë¯¸ì‚¬  ì´ìš©ê¸°ê°„  ë‹¨ ë¶„ì¢…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(K, Alpha), (ì°°êµ­, Noun), (DLwo, Alpha)], [(ë¡œ,...</td>\n",
       "      <td>ì°°êµ­ ë¡œí•œ íšŒì¥  ì†¡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(m, Alpha)], [(ê¹€ì •, Noun)], [(ìì£¼, Noun), (í†µì¼,...</td>\n",
       "      <td>ê¹€ì • ìì£¼í†µì¼ ìƒˆì—´ë‚˜ê°€ì•¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pIç¾(ë¯¸êµ­)ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(pI, Alpha), (ç¾, Foreign), ((, Punctuation),...</td>\n",
       "      <td>ç¾(ë¯¸êµ­)ëŒ€ì„ ì•ë‘ê³  ë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ynat-v1_train_00006</td>\n",
       "      <td>í”„ë¡œì•¼êµ¬ë¡¯TKIAsê´‘ì£¼ ê²½ê¸° yì²œì·¨ì†Œ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(í”„ë¡œì•¼êµ¬, Noun), (ë¡¯, Noun), (TKIAs, Alpha), (ê´‘ì£¼...</td>\n",
       "      <td>í”„ë¡œì•¼êµ¬ë¡¯ê´‘ì£¼ ê²½ê¸° ì²œì·¨ì†Œ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                            text  target  is_noise  \\\n",
       "0  ynat-v1_train_00000     ì •i íŒŒ1 ë¯¸ì‚¬z KT ì´ìš©ê¸°ê°„ 2e ë‹¨ Që¶„ì¢…U       4         1   \n",
       "1  ynat-v1_train_00001          Kì°°êµ­DLwo ë¡œL3í•œN íšŒì¥ 2 T0ì†¡       3         1   \n",
       "2  ynat-v1_train_00002               m ê¹€ì • ìì£¼í†µì¼ ìƒˆrì—´1ë‚˜ê°€ì•¼       2         1   \n",
       "4  ynat-v1_train_00004  pIç¾(ë¯¸êµ­)ëŒ€ì„ Iì•ë‘ê³  R2frë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”       6         1   \n",
       "6  ynat-v1_train_00006            í”„ë¡œì•¼êµ¬ë¡¯TKIAsê´‘ì£¼ ê²½ê¸° yì²œì·¨ì†Œ       1         1   \n",
       "\n",
       "                                         pos_tagging            pos_processed  \n",
       "0  [[(ì •, Noun), (i, Alpha)], [(íŒŒ, Noun), (1, Numb...       ì • íŒŒ ë¯¸ì‚¬  ì´ìš©ê¸°ê°„  ë‹¨ ë¶„ì¢…  \n",
       "1  [[(K, Alpha), (ì°°êµ­, Noun), (DLwo, Alpha)], [(ë¡œ,...              ì°°êµ­ ë¡œí•œ íšŒì¥  ì†¡  \n",
       "2  [[(m, Alpha)], [(ê¹€ì •, Noun)], [(ìì£¼, Noun), (í†µì¼,...            ê¹€ì • ìì£¼í†µì¼ ìƒˆì—´ë‚˜ê°€ì•¼  \n",
       "4  [[(pI, Alpha), (ç¾, Foreign), ((, Punctuation),...  ç¾(ë¯¸êµ­)ëŒ€ì„ ì•ë‘ê³  ë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”  \n",
       "6  [[(í”„ë¡œì•¼êµ¬, Noun), (ë¡¯, Noun), (TKIAs, Alpha), (ê´‘ì£¼...           í”„ë¡œì•¼êµ¬ë¡¯ê´‘ì£¼ ê²½ê¸° ì²œì·¨ì†Œ  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_words(morphs_lists):\n",
    "    def filter_and_join_morphemes(morphological_results):\n",
    "        # Alphaì™€ Punctuationì„ ì œì™¸í•œ ë¬¸ìë§Œ í•„í„°ë§\n",
    "        filtered_characters = [\n",
    "            word for word, pos in morphological_results if pos not in [\"Alpha\", \"Number\"]\n",
    "        ]\n",
    "        # í•„í„°ë§ëœ ë¬¸ìë“¤ì„ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ë¬¸ìì—´ë¡œ ê²°í•©\n",
    "        return \"\".join(filtered_characters)\n",
    "    return \" \".join(\n",
    "        [filter_and_join_morphemes(morphs_list) for morphs_list in morphs_lists]\n",
    "    )\n",
    "\n",
    "\n",
    "df[\"pos_processed\"] = df[\"pos_tagging\"].apply(join_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos_processed\"] = df[\"pos_processed\"].str.strip()\n",
    "df[\"pos_processed\"] = df[\"pos_processed\"].apply(lambda x: re.sub(r\"\\s+\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"ID\", \"pos_processed\", \"target\",\"is_noise\"]].rename(columns={\"pos_processed\": \"text\"})\n",
    "df.to_csv(\"4_d_1602_only_noise.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë¹„ ë…¸ì´ì¦ˆ ë°ì´í„° ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/3_d_2800_hanzi_dictionary.csv\")\n",
    "df = df[df[\"is_noise\"]==0]\n",
    "len(df)\n",
    "df.to_csv(\"5_d_1198_only_not_noise.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë¹„ ë…¸ì´ì¦ˆ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ BART ë…¸ì´ì¦ˆ ë³µêµ¬ ëª¨ë¸ í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"../data/5_d_1198_only_not_noise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "# ë…¸ì´ì¦ˆ ë¬¸ì¥ì—ì„œ ì¶”ì¶œí•œ íŠ¹ìˆ˜ë¬¸ì ëª©ë¡\n",
    "special_characters = ['â€¦', '.', 'Â·', '%', '\"', '-', '(', '|', '?', ',', '}', ':', '&', '_', '{', '~', '#', '\\\\', '*', ')', '$', '=', '+', '`', ';', \"'\", '!', '@', '<', '/', '>', '[', ']', '^', 'â†‘', 'âˆ¼', 'â†“', 'â†’', 'ãœ', 'ï¼‹', 'ã†', 'ã', 'ã¡', 'ï½', 'â‘¡', 'ï¼…', 'ã', 'â†”', 'â…”', 'ã', 'â‘£', 'â‘¢']\n",
    "\n",
    "def introduce_noise(text: str) -> str:\n",
    "    # í•œê¸€ ë¬¸ì ì°¾ê¸°\n",
    "    hangul_chars = re.findall(r'[ê°€-í£]', text)\n",
    "    # 20%ì— í•´ë‹¹í•˜ëŠ” ê°œìˆ˜ ê³„ì‚° (ìµœì†Œ 1ê°œ)\n",
    "    num_noise = max(1, int(len(hangul_chars) * 0.2))\n",
    "    \n",
    "    # ë³€ê²½í•  ì¸ë±ìŠ¤ ëœë¤ ì„ íƒ\n",
    "    indexes_to_replace = random.sample(range(len(hangul_chars)), num_noise)\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ìˆ˜ì •ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ë³€í™˜\n",
    "    noisy_text = list(text)\n",
    "    \n",
    "    for index in indexes_to_replace:\n",
    "        # ëœë¤ ë¬¸ì ìƒì„± (ìˆ«ì, ì˜ì–´ ëŒ€ì†Œë¬¸ì, ì •ì˜ëœ íŠ¹ìˆ˜ë¬¸ì)\n",
    "        random_char = random.choice(\n",
    "            [chr(x) for x in (\n",
    "                list(range(48, 58)) +     # ìˆ«ì (0-9)\n",
    "                list(range(65, 91)) +     # ëŒ€ë¬¸ì (A-Z)\n",
    "                list(range(97, 123))      # ì†Œë¬¸ì (a-z)\n",
    "            )] + special_characters            # ì •ì˜ëœ íŠ¹ìˆ˜ë¬¸ì\n",
    "        )\n",
    "        \n",
    "        # í•œê¸€ ë¬¸ìë¥¼ ëœë¤ ë¬¸ìë¡œ êµì²´\n",
    "        char_index = text.index(hangul_chars[index])\n",
    "        # noisy_text[char_index] = random_char\n",
    "        noisy_text[char_index] = \"\"\n",
    "        # ì‚¬ìš©ëœ í•œê¸€ ë¬¸ì ì œê±° (ê°™ì€ ë¬¸ì ì¤‘ë³µ ë³€ê²½ ë°©ì§€)\n",
    "        text = text[:char_index] + text[char_index + 1:]\n",
    "    \n",
    "    return ''.join(noisy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>noised_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©</td>\n",
       "      <td>ê°¤ë…¸íŠ¸8 ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ê¸ˆ ì–¼ë£©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00005</td>\n",
       "      <td>ç¾(ë¯¸êµ­)ì„±ì¸ 6ëª… ì¤‘ 1ëª…ê¼´ ë°°ìš°ìÂ·ì—°ì¸ ë¹š ë– ì•ˆì€ ì  ìˆë‹¤</td>\n",
       "      <td>ç¾(ë¯¸êµ­)ì„± 6 ì¤‘ 1ëª… ë°°ìš°ìÂ·ì—°ì¸  ë– ì•ˆì€ ì  ìˆë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00007</td>\n",
       "      <td>ì•„ê°€ë©”ì¦ˆ 33ë“ì  ìš°ë¦¬ì¹´ë“œ KBì†í•´ë³´í—˜ ì™„íŒŒ 3ìœ„ êµ³</td>\n",
       "      <td>ê°€ë©”ì¦ˆ 33ë“ì  ìš°ë¦¬ë“œ KBì†í•´ë³´í—˜ì™„íŒŒ 3ìœ„ êµ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00008</td>\n",
       "      <td>æœ´(ë°•)ëŒ€í†µë ¹ ì–¼ë§ˆë‚˜ ë§ì´ ë†€ë¼ì…¨ì–´ìš” ê²½ì£¼ ì§€ì§„í˜„ì¥ ë°©ë¬¸</td>\n",
       "      <td>æœ´(ëŒ€í†µë ¹ ì–¼ë§ˆë‚˜ ë§ì´ ë†€ë¼ì…¨ì–´ìš” ê²½ì£¼ ì§€ì§„í˜„ ë¬¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00009</td>\n",
       "      <td>ë“€ì–¼ì‹¬ ì•„ì´í° í•˜ë°˜ê¸° ì¶œì‹œì„¤ ì†”ì†” ì•Œëœ°í° ê¸°ëŒ€ê°</td>\n",
       "      <td>ì–¼ì‹¬ ì•„í° í•˜ë°˜ê¸° ì¶œì„¤ì†”ì†” ì•Œëœ°í° ê¸°ëŒ€ê°</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                text  \\\n",
       "0  ynat-v1_train_00003       ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©   \n",
       "1  ynat-v1_train_00005  ç¾(ë¯¸êµ­)ì„±ì¸ 6ëª… ì¤‘ 1ëª…ê¼´ ë°°ìš°ìÂ·ì—°ì¸ ë¹š ë– ì•ˆì€ ì  ìˆë‹¤   \n",
       "2  ynat-v1_train_00007       ì•„ê°€ë©”ì¦ˆ 33ë“ì  ìš°ë¦¬ì¹´ë“œ KBì†í•´ë³´í—˜ ì™„íŒŒ 3ìœ„ êµ³   \n",
       "3  ynat-v1_train_00008     æœ´(ë°•)ëŒ€í†µë ¹ ì–¼ë§ˆë‚˜ ë§ì´ ë†€ë¼ì…¨ì–´ìš” ê²½ì£¼ ì§€ì§„í˜„ì¥ ë°©ë¬¸   \n",
       "4  ynat-v1_train_00009          ë“€ì–¼ì‹¬ ì•„ì´í° í•˜ë°˜ê¸° ì¶œì‹œì„¤ ì†”ì†” ì•Œëœ°í° ê¸°ëŒ€ê°   \n",
       "\n",
       "                      noised_text  \n",
       "0     ê°¤ë…¸íŠ¸8 ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ê¸ˆ ì–¼ë£©  \n",
       "1  ç¾(ë¯¸êµ­)ì„± 6 ì¤‘ 1ëª… ë°°ìš°ìÂ·ì—°ì¸  ë– ì•ˆì€ ì  ìˆë‹¤  \n",
       "2      ê°€ë©”ì¦ˆ 33ë“ì  ìš°ë¦¬ë“œ KBì†í•´ë³´í—˜ì™„íŒŒ 3ìœ„ êµ³  \n",
       "3     æœ´(ëŒ€í†µë ¹ ì–¼ë§ˆë‚˜ ë§ì´ ë†€ë¼ì…¨ì–´ìš” ê²½ì£¼ ì§€ì§„í˜„ ë¬¸  \n",
       "4          ì–¼ì‹¬ ì•„í° í•˜ë°˜ê¸° ì¶œì„¤ì†”ì†” ì•Œëœ°í° ê¸°ëŒ€ê°  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"noised_text\"] = df_train[\"text\"].copy()\n",
    "df_train.loc[:,\"noised_text\"] = df_train[\"noised_text\"].apply(introduce_noise)\n",
    "df_train = df_train[[\"ID\",\"text\",\"noised_text\"]]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv(\"../data/4_d_1602_only_noise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1602"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = list(df_test[\"text\"])\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class TextReconstructor:\n",
    "    def __init__(self, model_name=\"gogamza/kobart-base-v2\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def reconstruct(self, corrupted_text, max_length=32):\n",
    "        # token_type_idsë¥¼ Falseë¡œ ì„¤ì •\n",
    "        inputs = self.tokenizer(corrupted_text, \n",
    "                              return_tensors=\"pt\", \n",
    "                              truncation=True, \n",
    "                              max_length=max_length,\n",
    "                              return_token_type_ids=False)  # ì´ ë¶€ë¶„ ì¶”ê°€\n",
    "        inputs = inputs.to(self.device)\n",
    "        \n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            num_beams=10,\n",
    "            no_repeat_ngram_size=2,\n",
    "            top_k=10,\n",
    "            top_p=0.95,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        reconstructed = self.tokenizer.decode(outputs[0], \n",
    "                                            skip_special_tokens=True)\n",
    "        return reconstructed\n",
    "\n",
    "\n",
    "\n",
    "class TextReconstructionDataset(Dataset):\n",
    "    def __init__(self, corrupted_texts, original_texts, tokenizer, max_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        print(\"í† í¬ë‚˜ì´ì§• ë°ì´í„°...\")\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        \n",
    "        for corrupt_text, orig_text in tqdm(zip(corrupted_texts, original_texts), \n",
    "                                          total=len(corrupted_texts),\n",
    "                                          desc=\"ë°ì´í„°ì…‹ ì¤€ë¹„ì¤‘\"):\n",
    "            # return_token_type_ids=False ì¶”ê°€\n",
    "            self.inputs.append(\n",
    "                self.tokenizer(\n",
    "                    corrupt_text,\n",
    "                    truncation=True,\n",
    "                    max_length=max_length,\n",
    "                    padding='max_length',\n",
    "                    return_tensors='pt',\n",
    "                    return_token_type_ids=False\n",
    "                )\n",
    "            )\n",
    "            self.targets.append(\n",
    "                self.tokenizer(\n",
    "                    orig_text,\n",
    "                    truncation=True,\n",
    "                    max_length=max_length,\n",
    "                    padding='max_length',\n",
    "                    return_tensors='pt',\n",
    "                    return_token_type_ids=False\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.inputs[idx][\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": self.inputs[idx][\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": self.targets[idx][\"input_ids\"].squeeze(0)\n",
    "        }\n",
    "\n",
    "\n",
    "def train_model(model, train_dataset, valid_dataset):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"../outputs\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        save_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_steps=100,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\",\n",
    "        # ì§„í–‰ ìƒí™© í‘œì‹œ í™œì„±í™”\n",
    "        disable_tqdm=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset\n",
    "    )\n",
    "    \n",
    "    print(\"ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "\n",
    "def prepare_and_train(df):\n",
    "    print(\"ë°ì´í„° ë¶„í•  ì¤‘...\")\n",
    "    train_df, valid_df = train_test_split(\n",
    "        df, \n",
    "        test_size=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\")\n",
    "    model_name = \"gogamza/kobart-base-v2\"\n",
    "    reconstructor = TextReconstructor(model_name)\n",
    "    \n",
    "    print(\"í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
    "    train_dataset = TextReconstructionDataset(\n",
    "        corrupted_texts=train_df['noised_text'].tolist(),\n",
    "        original_texts=train_df['text'].tolist(),\n",
    "        tokenizer=reconstructor.tokenizer\n",
    "    )\n",
    "    \n",
    "    print(\"ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
    "    valid_dataset = TextReconstructionDataset(\n",
    "        corrupted_texts=valid_df['noised_text'].tolist(),\n",
    "        original_texts=valid_df['text'].tolist(),\n",
    "        tokenizer=reconstructor.tokenizer\n",
    "    )\n",
    "    \n",
    "    train_model(reconstructor.model, train_dataset, valid_dataset)\n",
    "    \n",
    "    return reconstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì‹œì‘...\n",
      "ë°ì´í„° ë¶„í•  ì¤‘...\n",
      "ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\n",
      "í† í¬ë‚˜ì´ì§• ë°ì´í„°...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ì…‹ ì¤€ë¹„ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1078/1078 [00:00<00:00, 3644.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\n",
      "í† í¬ë‚˜ì´ì§• ë°ì´í„°...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ì…‹ ì¤€ë¹„ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:00<00:00, 3650.55it/s]\n",
      "/opt/conda/envs/main/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='405' max='405' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [405/405 01:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.214600</td>\n",
       "      <td>1.705800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.572300</td>\n",
       "      <td>0.211874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.154700</td>\n",
       "      <td>0.191062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/main/lib/python3.10/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'forced_eos_token_id': 1}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì €ì¥ ì¤‘...\n",
      "\n",
      "=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/main/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/main/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/main/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `10` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "print(\"í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì‹œì‘...\")\n",
    "reconstructor = prepare_and_train(df)\n",
    "\n",
    "print(\"ëª¨ë¸ ì €ì¥ ì¤‘...\")\n",
    "reconstructor.model.save_pretrained(\"./reconstructor/\")\n",
    "reconstructor.tokenizer.save_pretrained(\"./reconstructor\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===\")\n",
    "result_data = []\n",
    "for text in test_data:\n",
    "    reconstructed = reconstructor.reconstruct(text)\n",
    "    result_data.append(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>is_noise</th>\n",
       "      <th>denoised_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>ì • íŒŒ ë¯¸ì‚¬ ì´ìš©ê¸°ê°„ ë‹¨ ë¶„ì¢…</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ì •ì •íŒŒ ì¥ê±°ë¦¬ ë¯¸ì‚¬ ì´ìš©ê¸°ê°„ ë‹¨ê¸°ê°„ ë‚´ ë¶„ì¢…ì¢…ê¸°ê°„ë‹¨ ì¶”ì§„ê¸°ê°„ë„ ë‹¨ì‹œì¢…ì  ë‚´ë‹¬ ì¤‘ìˆœ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>ì°°êµ­ ë¡œí•œ íšŒì¥ ì†¡</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ì°°ìŠ¤ ë¡œí•œ íšŒì¥ ì†¡ì°°ì°° ì°° ì°°ì¦ˆë¼ì—˜ ì´ë¦¬ ì†¡ ì°°ì°°ë¼ì—˜ ì¡°ì§€ì•„ë¡œí•œ íšŒì¥ì„ ì†¡ì†¡ ì°°ì˜¥êµ­...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>ê¹€ì • ìì£¼í†µì¼ ìƒˆì—´ë‚˜ê°€ì•¼</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ê¹€ì •ì€ ìì£¼í†µì¼ ìƒˆ ì‹œëŒ€ ì—´ì–´ê°€ì•¼ í•œë‹¤ê³  ì„ ì–¸í–ˆë‹¤.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>ç¾(ë¯¸êµ­)ëŒ€ì„ ì•ë‘ê³  ë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>ç¾(ë¯¸êµ­)ëŒ€ì„ ì•ë‘ê³  ë‹¨ë°œì„± ë¹„ë‚œì— ë¹„í•´ ê°ì‹œ ê°•í™”í‚¤ë¡œ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00006</td>\n",
       "      <td>í”„ë¡œì•¼êµ¬ë¡¯ê´‘ì£¼ ê²½ê¸° ì²œì·¨ì†Œ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>í”„ë¡œì•¼êµ¬ ë¡¯ë°ë¡¯ë°ë¡¯ê´‘ì£¼ ê²½ê¸° ì²œì·¨ì†Œ ìŠ¹ë¦¬ì†Œì‹ì‚¼ì§„ì·¨ì†Œë¡œ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                     text  target  is_noise  \\\n",
       "0  ynat-v1_train_00000         ì • íŒŒ ë¯¸ì‚¬ ì´ìš©ê¸°ê°„ ë‹¨ ë¶„ì¢…       4         1   \n",
       "1  ynat-v1_train_00001               ì°°êµ­ ë¡œí•œ íšŒì¥ ì†¡       3         1   \n",
       "2  ynat-v1_train_00002            ê¹€ì • ìì£¼í†µì¼ ìƒˆì—´ë‚˜ê°€ì•¼       2         1   \n",
       "3  ynat-v1_train_00004  ç¾(ë¯¸êµ­)ëŒ€ì„ ì•ë‘ê³  ë‹¨ ë°œ ë¹„í•´ ê°ì‹œ ê°•í™”       6         1   \n",
       "4  ynat-v1_train_00006           í”„ë¡œì•¼êµ¬ë¡¯ê´‘ì£¼ ê²½ê¸° ì²œì·¨ì†Œ       1         1   \n",
       "\n",
       "                                       denoised_text  \n",
       "0  ì •ì •íŒŒ ì¥ê±°ë¦¬ ë¯¸ì‚¬ ì´ìš©ê¸°ê°„ ë‹¨ê¸°ê°„ ë‚´ ë¶„ì¢…ì¢…ê¸°ê°„ë‹¨ ì¶”ì§„ê¸°ê°„ë„ ë‹¨ì‹œì¢…ì  ë‚´ë‹¬ ì¤‘ìˆœ ...  \n",
       "1  ì°°ìŠ¤ ë¡œí•œ íšŒì¥ ì†¡ì°°ì°° ì°° ì°°ì¦ˆë¼ì—˜ ì´ë¦¬ ì†¡ ì°°ì°°ë¼ì—˜ ì¡°ì§€ì•„ë¡œí•œ íšŒì¥ì„ ì†¡ì†¡ ì°°ì˜¥êµ­...  \n",
       "2                     ê¹€ì •ì€ ìì£¼í†µì¼ ìƒˆ ì‹œëŒ€ ì—´ì–´ê°€ì•¼ í•œë‹¤ê³  ì„ ì–¸í–ˆë‹¤.\\n  \n",
       "3                      ç¾(ë¯¸êµ­)ëŒ€ì„ ì•ë‘ê³  ë‹¨ë°œì„± ë¹„ë‚œì— ë¹„í•´ ê°ì‹œ ê°•í™”í‚¤ë¡œ  \n",
       "4                      í”„ë¡œì•¼êµ¬ ë¡¯ë°ë¡¯ë°ë¡¯ê´‘ì£¼ ê²½ê¸° ì²œì·¨ì†Œ ìŠ¹ë¦¬ì†Œì‹ì‚¼ì§„ì·¨ì†Œë¡œ  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"denoised_text\"] = result_data\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[[\"ID\", \"denoised_text\", \"target\",\"is_noise\"]].rename(columns={\"denoised_text\": \"text\"})\n",
    "df_test[\"text\"] = df_test[\"text\"].str.replace(\"\\n\", \"\")\n",
    "df_test.to_csv(\"6_d_1602_kobart-denoise.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ë°ì´í„° ê²°í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"../data/5_d_1198_only_not_noise.csv\")\n",
    "df2 = pd.read_csv(\"../data/6_d_1602_kobart_denoise.csv\")\n",
    "\n",
    "df = pd.concat([df1,df2], axis=0)\n",
    "df[\"text\"] = df[\"text\"].str.strip()\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r\"\\s+\", \" \", x))\n",
    "\n",
    "print(len(df))\n",
    "df = df.sort_values(by=\"ID\", ascending=True)\n",
    "df = df[['ID', 'text', 'target']]\n",
    "df.to_csv(\"7_d_2800_kobart_denoise.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. cleanlab ë¼ë²¨ë§ ë° ì •ìƒ ë¼ë²¨ë§ ë³µêµ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë ¬\n",
    "df = pd.read_csv(\"../data/7_dr_2800_kobart_cleanlab.csv\")\n",
    "df = df.sort_values(by=\"ID\", ascending=True)\n",
    "df.to_csv(\"../data/7_dr_2800_kobart_cleanlab.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../data/7_dr_2800_kobart_cleanlab.csv\")\n",
    "df2 = pd.read_csv(\"../data/6_d_1602_kobart_denoise.csv\")\n",
    "\n",
    "# mergeë¥¼ ì‚¬ìš©í•˜ì—¬ ID ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ê²°í•©\n",
    "df1 = df1.merge(df2[['ID', 'target']], on='ID', how='left', suffixes=('', '_new'))\n",
    "df1['target'] = df1['target_new'].combine_first(df1['target'])\n",
    "df1 = df1.drop(columns=['target_new'])\n",
    "\n",
    "df1 = df1.sort_values(by=\"ID\", ascending=True)\n",
    "df1.to_csv(\"../data/7_dr_2800_kobart_cleanlab_update.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ë°”ê¾¸ê¸° ì „ ë¼ë²¨ê³¼ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_before = pd.read_csv(\"../data/7_d_2800_kobart_denoise.csv\")\n",
    "df_after = pd.read_csv(\"../data/7_dr_2800_kobart_cleanlab_update.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target_before</th>\n",
       "      <th>target_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ynat-v1_train_00005</td>\n",
       "      <td>ç¾(ë¯¸êµ­)ì„±ì¸ 6ëª… ì¤‘ 1ëª…ê¼´ ë°°ìš°ìÂ·ì—°ì¸ ë¹š ë– ì•ˆì€ ì  ìˆë‹¤</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ynat-v1_train_00007</td>\n",
       "      <td>ì•„ê°€ë©”ì¦ˆ 33ë“ì  ìš°ë¦¬ì¹´ë“œ KBì†í•´ë³´í—˜ ì™„íŒŒ 3ìœ„ êµ³</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ynat-v1_train_00008</td>\n",
       "      <td>æœ´(ë°•)ëŒ€í†µë ¹ ì–¼ë§ˆë‚˜ ë§ì´ ë†€ë¼ì…¨ì–´ìš” ê²½ì£¼ ì§€ì§„í˜„ì¥ ë°©ë¬¸</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ynat-v1_train_00011</td>\n",
       "      <td>NHíˆ¬ì 1ì›” ì˜µì…˜ ë§Œê¸°ì¼ ë§¤ë„ ìš°ì„¸</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                                text  target_before  \\\n",
       "3   ynat-v1_train_00003       ê°¤ë…¸íŠ¸8 ì£¼ë§ 27ë§ŒëŒ€ ê°œí†µ ì‹œì¥ì€ ë¶ˆë²• ë³´ì¡°ê¸ˆ ì–¼ë£©              5   \n",
       "5   ynat-v1_train_00005  ç¾(ë¯¸êµ­)ì„±ì¸ 6ëª… ì¤‘ 1ëª…ê¼´ ë°°ìš°ìÂ·ì—°ì¸ ë¹š ë– ì•ˆì€ ì  ìˆë‹¤              0   \n",
       "7   ynat-v1_train_00007       ì•„ê°€ë©”ì¦ˆ 33ë“ì  ìš°ë¦¬ì¹´ë“œ KBì†í•´ë³´í—˜ ì™„íŒŒ 3ìœ„ êµ³              4   \n",
       "8   ynat-v1_train_00008     æœ´(ë°•)ëŒ€í†µë ¹ ì–¼ë§ˆë‚˜ ë§ì´ ë†€ë¼ì…¨ì–´ìš” ê²½ì£¼ ì§€ì§„í˜„ì¥ ë°©ë¬¸              6   \n",
       "11  ynat-v1_train_00011                NHíˆ¬ì 1ì›” ì˜µì…˜ ë§Œê¸°ì¼ ë§¤ë„ ìš°ì„¸              1   \n",
       "\n",
       "    target_after  \n",
       "3            4.0  \n",
       "5            6.0  \n",
       "7            1.0  \n",
       "8            2.0  \n",
       "11           5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë‘ ë°ì´í„°í”„ë ˆì„ì„ IDì™€ text ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©\n",
    "df_merged = pd.merge(df_before, df_after, on=[\"ID\", \"text\"], suffixes=(\"_before\", \"_after\"))\n",
    "different_targets = df_merged[df_merged[\"target_before\"] != df_merged[\"target_after\"]]\n",
    "result_df = different_targets[['ID', 'text', 'target_before', 'target_after']]\n",
    "\n",
    "print(len(result_df))\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"label_diff.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "CleanLab ì²« ì‹œë„ì—ì„œ ë¼ë²¨ ì˜¤ë¥˜(= ë¹„ ë…¸ì´ì¦ˆ) ë°ì´í„°ëŠ” ê¸°ì¡´ í‹€ë¦° ë¼ë²¨ ê·¸ëŒ€ë¡œ ì˜ˆì¸¡í•  í™•ë¥ ì— íŒ¨ë„í‹°ë¥¼ í¬ê²Œ ì£¼ëŠ” ë°©ë²•ì„ ìƒê°í•  ìˆ˜ ìˆë‹¤.    \n",
    "ê·¸ëŸ¼ ë¼ë²¨ì´ í‹€ë¦¬ì§€ ì•Šì€ 200ê°œëŠ” ì–´ë–»ê²Œ êµ¬ë³„í•˜ëŠ”ê°€? -> ê¸°ì¡´ targetê³¼ ìƒˆë¡­ê²Œ ì˜ˆì¸¡í•œ targetì´ ê°™ì€ ê²ƒ ì¤‘ì—ì„œ í™•ë¥ ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ TOP 200ì„ ë½‘ì•„ì„œ ì¶”ë¡ í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
